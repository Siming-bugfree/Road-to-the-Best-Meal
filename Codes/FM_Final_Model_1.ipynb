{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection as cv\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_dic(dic, label2index=None, hold_num=None):\n",
    "    if label2index == None:\n",
    "        d = count(0)\n",
    "        label2index = defaultdict(lambda: next(d))  # 数值映射表\n",
    "\n",
    "    sample_num = len(list(dic.values())[0])  # 样本数\n",
    "    feat_num = len(list(dic.keys()))  # 特征数\n",
    "    total_value_num = sample_num * feat_num\n",
    "\n",
    "    col_ix = np.empty(total_value_num, dtype=int)\n",
    "\n",
    "    i = 0\n",
    "    for k, lis in dic.items():\n",
    "        col_ix[i::feat_num] = [label2index[str(k) + str(el)] for el in lis]\n",
    "        i += 1\n",
    "\n",
    "    row_ix = np.repeat(np.arange(sample_num), feat_num)\n",
    "    data = np.ones(total_value_num)\n",
    "\n",
    "    if hold_num is None:\n",
    "        hold_num = len(label2index)\n",
    "\n",
    "    left_data_index = np.where(col_ix < hold_num)  # 为了剔除不在train set中出现的test set数据\n",
    "\n",
    "    return csr.csr_matrix(\n",
    "        (data[left_data_index], (row_ix[left_data_index], col_ix[left_data_index])),\n",
    "        shape=(sample_num, hold_num)), label2index\n",
    "\n",
    "def batcher(X_, y_, batch_size=-1):\n",
    "\n",
    "    assert X_.shape[0] == len(y_)\n",
    "\n",
    "    n_samples = X_.shape[0]\n",
    "    if batch_size == -1:\n",
    "        batch_size = n_samples\n",
    "    if batch_size < 1:\n",
    "        raise ValueError('Parameter batch_size={} is unsupported'.format(batch_size))\n",
    "\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        upper_bound = min(i + batch_size, n_samples)\n",
    "        ret_x = X_[i:upper_bound]\n",
    "        ret_y = y_[i:upper_bound]\n",
    "        yield(ret_x, ret_y)\n",
    "\n",
    "def load_dataset():\n",
    "    cols = ['user_id', 'recipe_id', 'final_rating']\n",
    "    df = pd.read_csv('/Users/bytedance/Desktop/fm/data_for_recommendation.csv')\n",
    "    df = df[cols]\n",
    "    train_data, test_data = cv.train_test_split(df, test_size = 0.2)\n",
    "\n",
    "    x_train, label2index = vectorize_dic({'users': train_data['user_id'].values, 'recipe': train_data['recipe_id'].values})\n",
    "    x_test, label2index = vectorize_dic({'users': test_data['user_id'].values, 'recipe': test_data['recipe_id'].values}, label2index, x_train.shape[1])\n",
    "\n",
    "    y_train = train_data['final_rating'].values\n",
    "    y_test = test_data['final_rating'].values\n",
    "\n",
    "    x_train = x_train.todense()\n",
    "    x_test = x_test.todense()\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape:  (129000, 88332)\n",
      "x_test shape:  (32251, 88332)\n",
      "y_train shape:  (129000,)\n",
      "y_test shape:  (32251,)\n",
      "epoch:0\n",
      "batch train_mse=37.19145202636719, val_mse=37.42959976196289\n",
      "batch train_mse=36.570655822753906, val_mse=36.00130844116211\n",
      "batch train_mse=32.892845153808594, val_mse=34.59640884399414\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_dataset()\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "\n",
    "vec_dim = 10\n",
    "#Set Batch Size\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "learning_rate = 0.01\n",
    "sample_num, feat_num = x_train.shape\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, feat_num], name=\"input_x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None,1], name=\"ground_truth\")\n",
    "\n",
    "w0 = tf.get_variable(name=\"bias\", shape=(1), dtype=tf.float32)\n",
    "W = tf.get_variable(name=\"linear_w\", shape=(feat_num), dtype=tf.float32)\n",
    "V = tf.get_variable(name=\"interaction_w\", shape=(feat_num, vec_dim), dtype=tf.float32)\n",
    "\n",
    "linear_part = w0 + tf.reduce_sum(tf.multiply(x, W), axis=1, keepdims=True)\n",
    "interaction_part = 0.5 * tf.reduce_sum(tf.square(tf.matmul(x, V)) - tf.matmul(tf.square(x), tf.square(V)), axis=1, keepdims=True)\n",
    "y_hat = linear_part + interaction_part\n",
    "loss = tf.reduce_mean(tf.square(y - y_hat))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        if e == 1:\n",
    "            learning_rate = 0.001\n",
    "        step = 0\n",
    "        print(\"epoch:{}\".format(e))\n",
    "        for batch_x, batch_y in batcher(x_train, y_train, batch_size):\n",
    "            sess.run(train_op, feed_dict={x:batch_x, y:batch_y.reshape(-1, 1)})\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                for val_x, val_y in batcher(x_test, y_test):\n",
    "                    train_loss = sess.run(loss, feed_dict={x:batch_x, y:batch_y.reshape(-1, 1)})\n",
    "                    val_loss = sess.run(loss, feed_dict={x:val_x, y:val_y.reshape(-1, 1)})\n",
    "                    print(\"batch train_mse={}, val_mse={}\".format(train_loss, val_loss))\n",
    "                    train_loss_list.append(train_loss)\n",
    "                    val_loss_list.append(val_loss)\n",
    "            if step % 100 == 0:\n",
    "                train_loss_output = np.array([train_loss_list])\n",
    "                val_loss_output = np.array([val_loss_list])\n",
    "                result = np.concatenate((train_loss_output, val_loss_output))\n",
    "                filename = 'loss_{}_{}.csv'.format(e, step)\n",
    "                np.savetxt(filename, result.T, delimiter = ',') \n",
    "\n",
    "    for val_x, val_y in batcher(x_test, y_test):\n",
    "        val_loss = sess.run(loss, feed_dict={x: val_x, y: val_y.reshape(-1, 1)})\n",
    "        print(\"test set rmse = {}\".format(np.sqrt(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the loss\n",
    "\n",
    "train_loss_list = np.array([train_loss_list])\n",
    "val_loss_list = np.array([val_loss_list])\n",
    "result = np.concatenate((train_loss_list, val_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('loss.csv', result.T, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'loss_0_2.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}